{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/e/e5/Logo_%C3%A9cole_des_ponts_paristech.svg/676px-Logo_%C3%A9cole_des_ponts_paristech.svg.png\" width=\"200\"  height=\"200\" hspace=\"200\"/> </td>\n",
    "<td> <img src=\"https://pbs.twimg.com/profile_images/1156541928193896448/5ihYIbCQ_200x200.png\" width=\"200\" height=\"200\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h1><center>Session 4 - Data preparation</center></h1>\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"3\">This session is divided into **3** parts:\n",
    "- **Data exploration**\n",
    "- **Data preparation**\n",
    "- **Feature engineering**\n",
    "\n",
    "In each of these parts, some **guidelines** and **hints** are given for each task. \n",
    "Do not hesitate to check the links to documentation to understand the functions you use. \n",
    "    \n",
    "The goal of this session is to **create the dataset** that you will use as an **input for modeling sessions** (supervised and\n",
    "unsupervised).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Useful libraries and functions\n",
    "\n",
    "If you do not have the needed libraries already installed please run the following commands in a Terminal:\n",
    "- pip install pandas\n",
    "- pip install numpy\n",
    "- pip install matplotlib\n",
    "- pip install seaborn\n",
    "- pip install holidays\n",
    "- pip install vacances-scolaires-france"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import holidays\n",
    "from vacances_scolaires_france import SchoolHolidayDates\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some functions we wrote to help you, feel free to check them out to see what they do\n",
    "lang_to_keep = ['en', 'fr', 'es', 'it', 'ja', 'de']\n",
    "country_to_keep = ['FR', 'US', 'GB', 'DE', 'BE', 'CA']\n",
    "dict_genres = {\n",
    "    'Drame': 'Drame',\n",
    "    'Comédie': 'Comédie',\n",
    "    'Romance': 'Romance',\n",
    "    'Action': 'Action',\n",
    "    'Thriller': 'Action',\n",
    "    'Aventure': 'Action',\n",
    "    'Crime': 'Action',\n",
    "    'Guerre': 'Action',\n",
    "    'Western': 'Action',\n",
    "    'Familial': 'Familial',\n",
    "    'Animation': 'Familial',\n",
    "    'Fantastique': 'Fantastique',\n",
    "    'Science-Fiction': 'Fantastique',\n",
    "    'Horreur': 'Horreur',\n",
    "    'Mystère': 'Other',\n",
    "    'Musique': 'Other',\n",
    "    'Histoire': 'Other',\n",
    "    'Documentaire': 'Other',\n",
    "    'Téléfilm': 'Other'\n",
    "}\n",
    "\n",
    "\n",
    "def read_movies_entrees(path):\n",
    "    '''\n",
    "    Read the box office dataset \n",
    "    and casts it as an usable pandas DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        path to the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        Data as DataFrame\n",
    "    '''\n",
    "    bo = read_from_json(path)\n",
    "    bo = [\n",
    "        {\n",
    "            \"year\": item['year'], \n",
    "            \"title\": item['title'], \n",
    "            \"id\": int(item['id']), \n",
    "            \"sales\": item['first_week_sales'],\n",
    "            \"release_date\": item['release_date']\n",
    "        } for item in bo\n",
    "    ]\n",
    "    return pd.DataFrame(bo)\n",
    "\n",
    "\n",
    "def read_movies_features(path):\n",
    "    '''\n",
    "    Read the movie features dataset \n",
    "    and casts it as an usable pandas DataFrame\n",
    "    N.B: Fields that are not yet used are commented\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        path to the dataset\n",
    "    Returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        Data as DataFrame\n",
    "    '''\n",
    "    features = read_from_json(path)\n",
    "    features = [\n",
    "        {\n",
    "            \"is_adult\": item['adult'],\n",
    "            \"is_part_of_collection\": not not item['belongs_to_collection'],\n",
    "            \"collection_name\": item['belongs_to_collection']['name'] if item['belongs_to_collection'] != {} else None, # Currently simple bool, may be interesting to use a more complex feature later\n",
    "            \"budget\": item['budget'],\n",
    "            \"genres\": [ genre['name'] for genre in item['genres'] ], \n",
    "            \"original_language\": item['original_language'],\n",
    "            \"overview\": item['overview'], # Not used yet. Blob of text\n",
    "            \"production_countries\": [ country['iso_code'] for country in item['production_countries'] ],\n",
    "            \"languages\": [ language['iso_code'] for language in item['languages'] ],\n",
    "            \"tagline\": item['tagline'], # Not used yet. Blob of text\n",
    "            \"runtime\": item['runtime'],\n",
    "            \"cast\": item['cast'], # Not used yet. List of dicts with actor gender, name, id...\n",
    "            \"id\": int(item['id'])\n",
    "        } for item in features\n",
    "    ]\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "def read_from_json(path):\n",
    "    '''\n",
    "    Read and cast a json into a python object\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Path to json file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: Union[dict, list]\n",
    "        Json casted as python object\n",
    "    '''\n",
    "    with open(path, 'r') as infile:\n",
    "        data = json.load(infile)\n",
    "    return data\n",
    "\n",
    "\n",
    "def reduce_lang_categories(lang_list, lang_to_keep=lang_to_keep):\n",
    "    return list(set([el if el in lang_to_keep else 'other' for el in lang_list]))\n",
    "\n",
    "\n",
    "def reduce_country_categories(country_list, country_to_keep=country_to_keep):\n",
    "    return list(set([el if el in country_to_keep else 'OTHER' for el in country_list]))\n",
    "\n",
    "\n",
    "def reduce_genre_categories(genre_list, dict_genres=dict_genres):\n",
    "    return list(set([dict_genres[el] for el in genre_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first read the french movies \"entrées\"\n",
    "# Hint: you can use the function read_movies_entrees(), you just have to give the path to data as argument\n",
    "df_boxoffice = read_movies_entrees( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then fetch their main features.\n",
    "# Hint: you can use the function read_movies_features(), you just have to give the path to data as argument\n",
    "df_features = read_movies_features( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge both dataframes and store them in a new dataframe named \"data\"\n",
    "# Hint: you can use the function pd.merge(), you just have to find the right column to merge on (using the \"on\"\n",
    "# argument) \n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the first lines of your dataset. Feel free to do that every time you implement a new feature\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 EDA on sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the characteristics of the feature \"sales\" of the dataset using statistics\n",
    "# Hint: you can use the method .describe() on your dataframe on the right column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the characteristics of the feature \"sales\" of the dataset using graph\n",
    "# Hint: we advise you to use seaborn. Take a look at the example gallery and choose a graph that you think is \n",
    "# relevant to answer the question (https://seaborn.pydata.org/examples/index.html)\n",
    "# NB: if you want to scale your graph in order to make it readable add the following arguments in your function:\n",
    "# height=5, aspect=11/8 (ex: sns.lineplot(x=x, data=data, height=5, aspect=11/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any outlier in the dataset ? (e.g.: a movie with no sales)\n",
    "# Explain how you would like to handle this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 EDA on other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore other features of the dataset and keep note of your findings, it can help for the next parts\n",
    "# Hint: you can use .info() on your dataframe to gather information on variables types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of movies across years. Fill the arguments: x, data, kind below\n",
    "# Hint: we advise you to use seaborn. Take a look at the example gallery and choose a graph that you think is \n",
    "# relevant to answer the question (https://seaborn.pydata.org/examples/index.html)\n",
    "# NB: if you want to scale your graph in order to make it readable add the following arguments in your function:\n",
    "# height=5, aspect=11/8 (ex: sns.lineplot(x=x, data=data, height=5, aspect=11/8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the \"budget\" feature\n",
    "# Hint: you can use sns.displot() for continuous variables or sns.catplot() for categorical variables. Choose well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the \"is_part_of_collection\" feature\n",
    "# Hint: you can use sns.displot() for continuous variables or sns.catplot() for categorical variables. Choose well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the \"runtime\" feature\n",
    "# Hint: you can use sns.displot() for continuous variables or sns.catplot() for categorical variables. Choose well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For genres, languages, production countries, data comes in list for each movie, \n",
    "# we should preprocess these columns before plotting them. Here we flatten the lists into a bigger Series\n",
    "\n",
    "def flatten_list_series(column):\n",
    "    flattened_series = column.apply(pd.Series).stack().reset_index(drop=True)\n",
    "    flattened_series.name = column.name\n",
    "    return pd.DataFrame(flattened_series)\n",
    "\n",
    "# Try to plot a histogram for these categorical features using sns.catplot() with the following argument:\n",
    "# data=flatten_list_series(data['your_column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **To go further:**\n",
    "Explore the **\"cast\"** feature: \n",
    " - What insights can you find? \n",
    " - What kind of difficulties can you anticipate? \n",
    " - How do you think we can use this feature for our model later?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing/Zero values for sales\n",
    "# Hint: check the number of missing values to see which approach is the best suited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing/zero values for budget\n",
    "# Hint: check the number of missing values to see which approach is the best suited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing/zero values for runtime\n",
    "# Hint: check the number of missing values to see which approach is the best suited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go further:\n",
    "# Missing values for production countries\n",
    "# Hint: you can use the column \"original_language\" (e.g.: if original_language is \"FR\", the production country\n",
    "# is likely to be France)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Reduce cardinality for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of categories for: Original language\n",
    "# Hint: you can use the lang_to_keep variable from part 0, already imported. If the original language is in\n",
    "# lang_to_keep then we keep it, otherwise we set the value to 'other'\n",
    "data['original_language'] = data['original_language'].map(lambda x: x if x in ... else ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of categories for: languages, production_countries and genres\n",
    "# For example for languages:\n",
    "data['languages'] = data['languages'].map(lambda x: reduce_lang_categories(x))\n",
    "\n",
    "# Hint: for production_countries, you can use the reduce_country_categories() function from part 0,\n",
    "# already imported\n",
    "data['production_countries'] = \n",
    "\n",
    "# Hint: for production_countries, you can use the reduce_genre_categories() function from part 0,\n",
    "# already imported\n",
    "data['genres'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode is_part_of_collection into numerical\n",
    "# Hint: you can use a dictionary to map numerical values for each value of is_part_of_collection (True or False)\n",
    "data['is_part_of_collection'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode original_language\n",
    "# Hint: you can perform one-hot encoding with pd.get_dummies(), check documentation to see how to use it (\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features with multiple categories\n",
    "# Hint: you can use MultiLabelBinarizer()\n",
    "\n",
    "# Languages\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_lang = pd.DataFrame(mlb.fit_transform(data_final['languages']), columns=mlb.classes_, index=data_final.index)\n",
    "df_lang.columns = ['available_lang_' + col for col in df_lang.columns]\n",
    "\n",
    "# Genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_genre = \n",
    "\n",
    "# Production countries\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_country = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge encoded dataframes and store it into a new dataframe named data_final\n",
    "# Hint: you can use the merge function from pandas, pd.merge(), check documentation to see how to use it\n",
    "data_final = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load school holidays for France\n",
    "fr_holidays = SchoolHolidayDates()\n",
    "df_vacances = pd.DataFrame()\n",
    "for year in list(set(data_final['year'])):\n",
    "    df_vacances = pd.concat([df_vacances, pd.DataFrame.from_dict(fr_holidays.holidays_for_year(year)).T])\n",
    "\n",
    "# Load bank holidays for France\n",
    "df_jf = pd.DataFrame()\n",
    "for year in list(set(data_final['year'])):\n",
    "    df_jf = pd.concat([df_jf, pd.DataFrame([\n",
    "        {'date': el[0], 'jour_ferie': el[1]} for el in sorted(holidays.FRA(years=year).items())])])\n",
    "    \n",
    "# Merge school and bank holidays\n",
    "df_holidays = pd.merge(df_vacances, df_jf, how='outer', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features from df_holidays dataframes (school holidays and bank holidays):\n",
    "# - 3 binary features for school holidays, taking 1 if the given zone is on holiday, else 0 (vacances_zone_a, \n",
    "# vacances_zone_b, vacances_zone_c)\n",
    "# - 1 binary feature for bank holiday, taking 1 if it is a bank holiday, else 0\n",
    "# - To go further: Try to create a combined feature with school and bank holidays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_holidays that contains newly created features with the main dataframe and store it into data_final\n",
    "df_holidays['date'] = df_holidays['date'].map(lambda x: str(x))\n",
    "data_final = pd.merge(data_final, df_holidays, how='left', left_on='release_date', right_on='date').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create calendar features for month: \n",
    "# - the number of the month (named \"month\")\n",
    "\n",
    "# To go further: try to transform the \"month\" variable using a mathematical function to capture cyclicity\n",
    "# (January (1) comes right after December (12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection with an high number of movies are often sagas that have worked well (ex: Star Wars, Fast and\n",
    "# Furious, ...)\n",
    "# We can therefore use the variable \"is_part_of_collection\" to compute the number of movies per collection\n",
    "# Hint: to create this kind of feature, you can use the .value_counts() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go (much) further:\n",
    "# Movies from a same collection will tend to have a similar number of sales\n",
    "# We can therefore use the variable \"is_part_of_collection\" to calculate an average of the sales of previous films\n",
    "# from the same collection\n",
    "# Hint: to create this kind of feature, you can use the .groupby(), .transform(), .rolling(), .mean() and .shift()\n",
    "# methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 [OPTIONAL] Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the \"cast\" feature to understand its structure and try to identify its limits if not done in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A movie with bankable actors is more likely to have an important number of entrees than a movie with unknown \n",
    "# actors\n",
    "# We can leverage the \"cast\" feature that contains information about actors and their popularity for each movie\n",
    "# to create several features, for example:\n",
    "# - for one movie, compute the mean popularity of its 3 main actors\n",
    "# - for one movie, compute the mean popularity of its 5 main actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go (much much) further:\n",
    "# In the same vein, we could create features taking into account sales of previous movies per actor and create \n",
    "# features that represent:\n",
    "# - for one movie, the mean of sales of previous movies of the #1 actor\n",
    "# - for one movie, the mean of sales of previous movies of the #2 actor\n",
    "# - for one movie, the mean of sales of previous movies of the #3 actor\n",
    "# - for one movie, the mean or the maximum of the three features above\n",
    "# This would also give an idea of an actor's \"popularity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Save file for next session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns for modeling (not numerical columns, raw columns that have been transformed, ...)\n",
    "# Hint: you can use the .drop() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values due to feature engineering if any\n",
    "# Hint: you can use the .fillna() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "# Hint: you can use the .to_csv() method\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
