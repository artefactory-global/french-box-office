{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assured-feature",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/e/e5/Logo_%C3%A9cole_des_ponts_paristech.svg/676px-Logo_%C3%A9cole_des_ponts_paristech.svg.png\" width=\"200\"  height=\"200\" hspace=\"200\"/> </td>\n",
    "<td> <img src=\"https://pbs.twimg.com/profile_images/1156541928193896448/5ihYIbCQ_200x200.png\" width=\"200\" height=\"200\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h1><center>Advanced Modelling</center></h1>\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"3\">This session is divided into **2** parts:\n",
    "- **1 - Example with computer vision: handwritten digit classifier**\n",
    "- **2 - Deep Learning with tabular data: french-box-office**\n",
    "\n",
    "In each of these parts, some **guidelines** and **hints** are given for each task. \n",
    "Do not hesitate to check the links to documentation to understand the functions you use. \n",
    "    \n",
    "The goal of this session is to create a regression using deep learning. We will use an example based on computer vision and we will try to create a fully connected network for our regression problem. All the work is based on pytorch and the computer vision is taken from a tutorial done by the fastai team.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-gardening",
   "metadata": {},
   "source": [
    "# Classification: handwritten digit recognition -- MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-clarity",
   "metadata": {},
   "source": [
    "#### Getting dataset from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "innovative-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hindu-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import pickle\n",
    "### the dataset comes already with a training data and a validation data. We will use them as is\n",
    "### The data is stored as numpy array\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "featured-creek",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Let's visualize an image \n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[4].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accomplished-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uniform-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before we proceed, we will transform the numpy to tensor as it is easier to work with for deep learning\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "divine-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets build a dataset using the TensorDataset of pytorch library\n",
    "### A dataset object is a convenient way to have x (features, here the image) and y(the label, which digit is it) \n",
    "### at the same time\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "secondary-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataloader\n",
    "### A dataloader is also convenient object for deep learning as we can iterate the dataset by batch\n",
    "### All you have to do is pick a batch size and by iterationg over the dataloader, you will receive batch of your dataset\n",
    "###\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs= 64\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(train_ds, batch_size=bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fuzzy-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "### model\n",
    "from torch import nn\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "about-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN.Sequential allows us to easily stack layers to build an network of convolutionnal layers. It is usefull\n",
    "### here because we are dealing with images\n",
    "### The first layer is just here to transform the vector into a 28x28 pixel squarre image\n",
    "### ReLu is an activation function \n",
    "### AvgPool2d\n",
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "flexible-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "### optimizer\n",
    "from torch import optim\n",
    "### picking a learning rate\n",
    "lr = 0.1  \n",
    "### choosing an optmizer to run our gradient descent algorithm. This is a stochastic gradient descent. Momentum\n",
    "### helps the training go faster but it is optional\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "supported-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "import torch.nn.functional as F\n",
    "### we pick the cross entropy loss as we are facing a classification problem\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "jewish-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    ''' Will compute the loss for a batch and the gradient if opt is given'''\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "christian-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "### choose a number of epochs for training\n",
    "epochs= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rotary-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4759799555015564\n",
      "1 0.28878126936912535\n",
      "2 0.2655349987316132\n",
      "3 0.1844113236618042\n",
      "4 0.1703712854242325\n",
      "5 0.159769218416214\n",
      "6 0.13608565761566163\n",
      "7 0.13180594417095184\n",
      "8 0.13037776471853257\n",
      "9 0.11728199555397034\n"
     ]
    }
   ],
   "source": [
    "### call fit to train the model using the dataloaders for train and valid and printing the loss for validation set\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brazilian-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = model(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cloudy-reproduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9629)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Accuracy of the classifier. This is the metric that tells us how good we can recognize handwritten digits\n",
    "(torch.argmax(predictions,dim=1)==y_valid).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-actress",
   "metadata": {},
   "source": [
    "# Regression with Deep Learning -- French Box Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "spare-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fef94216eb0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-coverage",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "supposed-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def load_dataset(path):\n",
    "    print(f\"loading raw data..\")\n",
    "    data = pd.read_csv(path)\n",
    "    data.drop(['title'], axis = 1, inplace = True)\n",
    "    return data\n",
    "\n",
    "def clean_data(data, drop_2020=True):\n",
    "    print(f\"cleaning data..\")\n",
    "    data = data.dropna()\n",
    "    if drop_2020:\n",
    "        data = data.query(\"year != 2020\")\n",
    "    data = data.sort_values(by='release_date')\n",
    "    data.release_date = pd.to_datetime(data.release_date)\n",
    "    data.index = data.release_date\n",
    "    data = data.drop(columns = ['index', 'release_date', 'year'], errors='ignore')\n",
    "    return data\n",
    "\n",
    "def train_test_split_by_date(df: pd.DataFrame, split_date_val: str, split_date_test: str):\n",
    "    \"\"\"Split dataset according to a split date in format \"YYYY-MM-DD\"\n",
    "    - train: [:split_date_1[\n",
    "    - validation: [split_date_1: split_date_2[\n",
    "    - test: [split_date_2:[\n",
    "    \"\"\"\n",
    "    train = df.loc[:split_date_val].copy()\n",
    "    validation = df.loc[split_date_val:split_date_test].copy()\n",
    "    test = df.loc[split_date_test:].copy()\n",
    "    return train, validation, test\n",
    "\n",
    "def get_x_y(dataset):\n",
    "    target = dataset.sales\n",
    "    target = target.astype(float)\n",
    "    features = dataset.drop(columns = ['sales'], errors='ignore')\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "decimal-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data..\n",
      "cleaning data..\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/yaguethiam/Ponts/data_prepared_session4.csv'\n",
    "raw_data = load_dataset(path)\n",
    "\n",
    "data = clean_data(raw_data, drop_2020=False)\n",
    "train_data, validation_data, test_data = train_test_split_by_date(data,\n",
    "                                                                  '2018-01-01',\n",
    "                                                                  '2020-01-01')\n",
    "train_x, train_y = get_x_y(train_data)\n",
    "validation_x, validation_y = get_x_y(validation_data)\n",
    "test_x, test_y = get_x_y(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "alike-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a TensorDataset for train and validation \n",
    "### Dont forget to take the log of y \n",
    "### convert the torch to float \n",
    "x_train  = torch.tensor(train_x.values).float()\n",
    "x_valid  = torch.tensor(validation_x.values).float()\n",
    "\n",
    "y_train = torch.tensor(train_y.values).log().unsqueeze(1).float()\n",
    "y_valid = torch.tensor(validation_y.values).log().unsqueeze(1).float()\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "casual-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a Dataloader\n",
    "### choose a batch size, 500 is a good choice but feel free to change it\n",
    "\n",
    "bs = \n",
    "train_dl = DataLoader(?, batch_size=bs, shuffle=?)\n",
    "valid_dl = DataLoader(?, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cognitive-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute mean and std of the training data\n",
    "### why do we only compute the mean and std deviation of the training data for the normalization to come?\n",
    "\n",
    "train_mean,train_std = ?\n",
    "\n",
    "def normalize(x, m=train_mean, s=train_std):\n",
    "    '''\n",
    "    Normalize a dataset x with the mean m and the std dev s\n",
    "    '''\n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "native-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the number of input features\n",
    "m = x_train.shape[?]\n",
    "\n",
    "### choose a number of hidden layers\n",
    "nh = ?\n",
    "\n",
    "### choose a value for the dropout probability. 0.15 is a good choice\n",
    "dropout = ?\n",
    "\n",
    "## add weight decay ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "independent-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "### build a sequential model using Lambda (defined above, use the appropriate function)\n",
    "### Use also nn.Linear and nn.Dropout if you want to add regularization\n",
    "### nn.ReLu if you want to build a non-linear model\n",
    "### organize the layer correctly. Remember we want to normalize before anything happens\n",
    "### and the output layer should be of 1 dimension as we are doing a regression\n",
    "\n",
    "model = nn.Sequential(?,?,?,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "initial-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose an optimizer which uses gradient descent\n",
    "### give your optimizer the right parameters\n",
    "### add momentum to it (it will help accelarate training, set it to 0.9)\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "lr = ?   # learning rate\n",
    "momentum = ?\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "color-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose a number of epochs. The goal here is a number of epoch enough for your model to train and to not overfitt\n",
    "### you can try many values, the training is fast\n",
    "### choose a loss function, remember what we did in the last session (it will not be the same but you can choose one that will be very similar)\n",
    "\n",
    "epochs = ? # how many epochs to train for\n",
    "loss_func = ? #loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "### call the fit to train your model\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "charitable-duncan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1731, grad_fn=<L1LossBackward>)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### compute the loss function on the validation set\n",
    "loss_func(?, ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "neither-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "religious-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"in percent\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred)/y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "aware-binding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.3429355621338"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### compute the new MAPE on the validation set\n",
    "mean_absolute_percentage_error(model(x_valid).exp().detach().numpy(), y_valid.exp().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-donna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
