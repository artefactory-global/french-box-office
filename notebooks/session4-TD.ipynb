{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/e/e5/Logo_%C3%A9cole_des_ponts_paristech.svg/676px-Logo_%C3%A9cole_des_ponts_paristech.svg.png\" width=\"200\"  height=\"200\" hspace=\"200\"/> </td>\n",
    "<td> <img src=\"https://pbs.twimg.com/profile_images/1156541928193896448/5ihYIbCQ_200x200.png\" width=\"200\" height=\"200\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h1><center>Session 4 - Data preparation</center></h1>\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"3\">This session is divided into **3** parts:\n",
    "- **Data exploration**\n",
    "- **Data preparation**\n",
    "- **Feature engineering**\n",
    "\n",
    "In each of these parts, some **guidelines** and **hints** are given for each task. \n",
    "Do not hesitate to check the links to documentation to understand the functions you use. \n",
    "    \n",
    "The goal of this session is to **create the dataset** that you will use as an **input for modeling sessions** (supervised and\n",
    "unsupervised).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Useful libraries and functions\n",
    "\n",
    "Guide installation libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from lib.preprocessing.load import read_movies_entrees\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import holidays\n",
    "from vacances_scolaires_france import SchoolHolidayDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some functions we wrote to help you, feel free to check them out to see what they do\n",
    "from session5 import (\n",
    "    read_movies_features, reduce_lang_categories, reduce_country_categories, reduce_genre_categories, apply_cos,\n",
    "    lang_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first read the french movies \"entrÃ©es\"\n",
    "# Hint: you can use the function read_movies_entrees(), you just have to give the path to data as argument\n",
    "df_boxoffice = read_movies_entrees( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then fetch their main features.\n",
    "# Hint: you can use the function read_movies_features(), you just have to give the path to data as argument\n",
    "df_features = read_movies_features( ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge both dataframes and store them in a new dataframe named \"data\"\n",
    "# Hint: you can use the function pd.merge(), you just have to find the right column to merge on (using the \"on\"\n",
    "# argument) \n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the first lines of your dataset. Feel free to do that every time you implement a new feature\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 EDA on sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the characteristics of the feature \"sales\" of the dataset using statistics\n",
    "# Hint: you can use the method .describe() on your dataframe on the right column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the characteristics of the feature \"sales\" of the dataset using graph\n",
    "# Hint: you can make an histogram with the sns.displot() function, check the documentation to see how to use it\n",
    "# (https://seaborn.pydata.org/generated/seaborn.displot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any outlier in the dataset ? (e.g.: a movie with no sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 EDA on other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore other features of the dataset and keep note of your findings, it can help for the next parts\n",
    "# Hint: you can use .info() on your dataframe to gather information on variables types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of movies across years. Fill the arguments: x, data, kind below\n",
    "# Hint: the library seaborn has a specific function for categorical plot that can be called by sns.catplot()), \n",
    "# check the documentation to see how to use it (https://seaborn.pydata.org/generated/seaborn.catplot.html)\n",
    "sns.catplot(x=, data=, kind=, height=8.27, aspect=11.7/8.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the \"budget\" feature\n",
    "# Hint: you can use sns.displot() for continuous variables or sns.catplot() for categorical variables. Choose well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the \"is_part_of_collection\" feature\n",
    "# Hint: you can use sns.displot() for continuous variables or sns.catplot() for categorical variables. Choose well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the \"runtime\" feature\n",
    "# Hint: you can use sns.displot() for continuous variables or sns.catplot() for categorical variables. Choose well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For genres, languages, production countries, data comes in list for each movie, \n",
    "# we should preprocess these columns before plotting them. Here we flatten the lists into a bigger Series\n",
    "\n",
    "def flatten_list_series(column):\n",
    "    flattened_series = column.apply(pd.Series).stack().reset_index(drop=True)\n",
    "    flattened_series.name = column.name\n",
    "    return pd.DataFrame(flattened_series)\n",
    "\n",
    "# Try to plot a histogram for these categorical features using sns.catplot() with the following argument:\n",
    "# data=flatten_list_series(data['your_column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **To go further:**\n",
    "Explore the **\"cast\"** feature: \n",
    " - What insights can you find? \n",
    " - What kind of difficulties can you anticipate? \n",
    " - How do you think we can use this feature for our model later?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing/Zero values for sales\n",
    "# Hint: check the number of missing values to see which approach is the best suited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing/zero values for budget\n",
    "# Hint: check the number of missing values to see which approach is the best suited\n",
    "data.loc[data['budget'] == 0, 'budget'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing/zero values for runtime\n",
    "# Hint: check the number of missing values to see which approach is the best suited\n",
    "data.loc[(data['runtime'].isnull() == True) | (data['runtime'] == 0), 'runtime'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go further:\n",
    "# Missing values for production countries\n",
    "# Hint: you can use the column \"original_language\" (e.g.: if original_language is \"FR\", the production country\n",
    "# is likely to be France)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Reduce cardinality for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of categories for: Original language\n",
    "# Hint: you can use the lang_to_keep variable from session5.py, already imported. If the original language is in\n",
    "# lang_to_keep then we keep it, otherwise we set the value to 'other'\n",
    "data['original_language'] = data['original_language'].map(lambda x: x if x in ... else ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of categories for: languages, production_countries and genres\n",
    "# For example for languages:\n",
    "data['languages'] = data['languages'].map(lambda x: reduce_lang_categories(x))\n",
    "\n",
    "# Hint: for production_countries, you can use the reduce_country_categories() function from session5.py,\n",
    "# already imported\n",
    "data['production_countries'] = \n",
    "\n",
    "# Hint: for production_countries, you can use the reduce_genre_categories() function from session5.py,\n",
    "# already imported\n",
    "data['genres'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode is_part_of_collection into numerical\n",
    "# Hint: you can use a dictionary to map numerical values for each value of is_part_of_collection (True or False)\n",
    "data['is_part_of_collection'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode original_language\n",
    "# Hint: you can perform one-hot encoding with pd.get_dummies(), check documentation to see how to use it (\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features with multiple categories\n",
    "# Hint: you can use MultiLabelBinarizer()\n",
    "\n",
    "# Languages\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_lang = pd.DataFrame(mlb.fit_transform(data_final['languages']), columns=mlb.classes_, index=data_final.index)\n",
    "df_lang.columns = ['available_lang_' + col for col in df_lang.columns]\n",
    "\n",
    "# Genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_genre = \n",
    "\n",
    "# Production countries\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_country = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge encoded dataframes and store it into a new dataframe named data_final\n",
    "# Hint: you can use the merge function from pandas, pd.merge(), check documentation to see how to use it\n",
    "data_final = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load school holidays for France\n",
    "fr_holidays = SchoolHolidayDates()\n",
    "df_vacances = pd.DataFrame()\n",
    "for year in list(set(data_final['year'])):\n",
    "    df_vacances = pd.concat([df_vacances, pd.DataFrame.from_dict(fr_holidays.holidays_for_year(year)).T])\n",
    "\n",
    "# Load bank holidays for France\n",
    "df_jf = pd.DataFrame()\n",
    "for year in list(set(data_final['year'])):\n",
    "    df_jf = pd.concat([df_jf, pd.DataFrame([\n",
    "        {'date': el[0], 'jour_ferie': el[1]} for el in sorted(holidays.FRA(years=year).items())])])\n",
    "    \n",
    "# Merge school and bank holidays\n",
    "df_holidays = pd.merge(df_vacances, df_jf, how='outer', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features from df_holidays dataframes (school holidays and bank holidays):\n",
    "# - 3 binary features for school holidays, taking 1 if the given zone is on holiday, else 0 (vacances_zone_a, \n",
    "# vacances_zone_b, vacances_zone_c)\n",
    "# - 1 binary feature for bank holiday, taking 1 if it is a bank holiday, else 0\n",
    "# - To go further: Try to create a combined feature with school and bank holidays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_holidays that contains newly created features with the main dataframe and store it into data_final\n",
    "df_holidays['date'] = df_holidays['date'].map(lambda x: str(x))\n",
    "data_final = pd.merge(data_final, df_holidays, how='left', left_on='release_date', right_on='date').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create calendar features for month: \n",
    "# - the number of the month (named \"month\")\n",
    "\n",
    "# To go further: try to transform the \"month\" variable using a mathematical function to capture cyclicity\n",
    "# (January (1) comes right after December (12))\n",
    "# Hint: explore the functions available in session5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection with an high number of movies are often sagas that have worked well (ex: Star Wars, Fast and\n",
    "# Furious, ...)\n",
    "# We can therefore use the variable \"is_part_of_collection\" to compute the number of movies per collection\n",
    "# Hint: to create this kind of feature, you can use the .value_counts() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go (much) further:\n",
    "# Movies from a same collection will tend to have a similar number of sales\n",
    "# We can therefore use the variable \"is_part_of_collection\" to calculate an average of the sales of previous films\n",
    "# from the same collection\n",
    "# Hint: to create this kind of feature, you can use the .groupby(), .transform(), .rolling(), .mean() and .shift()\n",
    "# methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 [OPTIONAL] Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the \"cast\" feature to understand its structure and try to identify its limits if not done in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A movie with bankable actors is more likely to have an important number of entrees than a movie with unknown \n",
    "# actors\n",
    "# We can leverage the \"cast\" feature that contains information about actors and their popularity for each movie\n",
    "# to create several features, for example:\n",
    "# - for one movie, compute the mean popularity of its 3 main actors\n",
    "# - for one movie, compute the mean popularity of its 5 main actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To go (much much) further:\n",
    "# In the same vein, we could create features taking into account sales of previous movies per actor and create \n",
    "# features that represent:\n",
    "# - for one movie, the mean of sales of previous movies of the #1 actor\n",
    "# - for one movie, the mean of sales of previous movies of the #2 actor\n",
    "# - for one movie, the mean of sales of previous movies of the #3 actor\n",
    "# - for one movie, the mean or the maximum of the three features above\n",
    "# This would also give an idea of an actor's \"popularity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Save file for next session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns for modeling (not numerical columns, raw columns that have been transformed, ...)\n",
    "# Hint: you can use the .drop() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values due to feature engineering if any\n",
    "# Hint: you can use the .fillna() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "# Hint: you can use the .to_csv() method\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
