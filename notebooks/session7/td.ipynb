{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extra-revelation",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/e/e5/Logo_%C3%A9cole_des_ponts_paristech.svg/676px-Logo_%C3%A9cole_des_ponts_paristech.svg.png\" width=\"200\"  height=\"200\" hspace=\"200\"/> </td>\n",
    "<td> <img src=\"https://pbs.twimg.com/profile_images/1156541928193896448/5ihYIbCQ_200x200.png\" width=\"200\" height=\"200\" /> </td>\n",
    "</tr></table>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<h1><center>Session 7 - Model Evaluation and Selection</center></h1>\n",
    "\n",
    "\n",
    "\n",
    "<font size=\"3\">This session is divided into **2** parts:\n",
    "- **Model selection**\n",
    "- **Model optimization:**\n",
    ">  * 1-Features selection\n",
    ">  * 2-Hyperparameters optimization\n",
    "\n",
    "In each of these parts, some **guidelines** and **hints** are given for each task. \n",
    "Do not hesitate to check the links to documentation to understand the functions you use. \n",
    "    \n",
    "The goal of this session is to **select a model** that you will use as your best candidate and optimize it to get the best out of it.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-reverse",
   "metadata": {},
   "source": [
    "# Session 5 modelling wrap up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics._regression import _check_reg_targets\n",
    "\n",
    "#models\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    print(f\"loading raw data..\")\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def clean_data(data, drop_2020=True):\n",
    "    print(f\"cleaning data..\")\n",
    "    data = data.dropna()\n",
    "    if drop_2020:\n",
    "        data = data.query(\"year != 2020\")\n",
    "    data = data.sort_values(by='release_date')\n",
    "    data.release_date = pd.to_datetime(data.release_date)\n",
    "    data.index = data.release_date\n",
    "    data = data.drop(columns = ['index', 'release_date', 'year'], errors='ignore')\n",
    "    return data\n",
    "\n",
    "def train_test_split_by_date(df: pd.DataFrame, split_date: str):\n",
    "    \"\"\"Split dataset according to a split date in format \"YYYY-MM-DD\"\n",
    "    - train: [:split_date[\n",
    "    - test: [split_date:]\n",
    "    \"\"\"\n",
    "    train = df.loc[:split_date].copy()\n",
    "    test = df.loc[split_date:].copy()\n",
    "    return train, test\n",
    "\n",
    "def get_x_y(dataset):\n",
    "    target = dataset.sales\n",
    "    target = target.astype(float)\n",
    "    features = dataset.drop(columns = ['sales'], errors='ignore')\n",
    "    return features, target\n",
    "          \n",
    "def transform_target(target, forward = True):\n",
    "    if forward == True: target_tf = [np.log(x) for x in target]\n",
    "    else: target_tf = [np.exp(x) for x in target]\n",
    "    return target_tf  \n",
    "          \n",
    "def get_evaluation_metrics(y_test, y_pred, y_train=None) -> dict:\n",
    "    metrics = {\n",
    "        'mape': mean_absolute_percentage_error(y_test, y_pred),\n",
    "        'rmse': mean_squared_error(y_test, y_pred, squared=False),\n",
    "        'mae': mean_absolute_error(y_test, y_pred),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \"\"\"in percent\"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred)/y_true)) * 100\n",
    "\n",
    "def prettify_metrics(metrics: dict) -> str:\n",
    "    output = [f\"Evaluation:\\n{'-'*10}\"]\n",
    "    for name, metric in metrics.items():\n",
    "        output.append((f'- {name.upper()}: {round(metric, 2)}'))\n",
    "    return '\\n'.join(output) +'\\n'\n",
    "\n",
    "def train(lr, features, target, transformer = None):\n",
    "    print(f\"start fitting a {lr.__class__}...\")\n",
    "    if transformer:\n",
    "        lr = lr.fit(features, transformer(target, forward = True))\n",
    "    predicted_target = lr.predict(features)\n",
    "    if transformer:\n",
    "        predicted_target = transformer(predicted_target, forward= False)\n",
    "    print(prettify_metrics(get_evaluation_metrics(target, predicted_target)))\n",
    "    \n",
    "    return lr\n",
    "\n",
    "def evaluate(lr, features, target, transformer=None, ret=False):\n",
    "    predicted_target = lr.predict(features)\n",
    "    if transformer:\n",
    "        predicted_target = transformer(predicted_target, forward= False)\n",
    "    \n",
    "    print(prettify_metrics(get_evaluation_metrics(target, predicted_target)))\n",
    "    if ret==True:\n",
    "        return get_evaluation_metrics(target, predicted_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-yeast",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-benjamin",
   "metadata": {},
   "source": [
    "## Q1 - Train/Test --> Train/Validation/Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-design",
   "metadata": {},
   "source": [
    "#### What if we want to use 2020 as testing set ?\n",
    "Update the split function so that we can keep 2020 as testing set\n",
    "> -  Modify the function **train_test_split_date** to produce a **train_validation_test_split_date**\n",
    "> -  Hint: add another date split to the function or use the function twice\n",
    "> - Your function should return 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_date(df: pd.DataFrame, split_date: str ...):\n",
    "    \n",
    "    ...\n",
    "                             \n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-nowhere",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/yaguethiam/Ponts/data_prepared_ponts_v4.csv'\n",
    "raw_data = load_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_data(raw_data)\n",
    "train_data, validation_data, test_data = train_test_split_by_date(data,\n",
    "                                                                  '2018-01-01',\n",
    "                                                                  '2020-01-01')\n",
    "train_x, train_y = get_x_y(train_data)\n",
    "validation_x, validation_y = get_x_y(validation_data)\n",
    "test_x, test_y = get_x_y(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-welding",
   "metadata": {},
   "source": [
    "# Models training\n",
    "> - run a linear regression, a Random Forest and a LGBM on the dataset without testing\n",
    "> - what metrics is more representative for our problem?\n",
    "> - compare the models\n",
    "> - select the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-money",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = \n",
    "lr = train(learner, train_x, train_y, transformer = transform_target)\n",
    "print(\"Evaluate on validation set ...\")\n",
    "evaluate(lr, validation_x, validation_y, transformer = transform_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-lewis",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-evening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "retired-central",
   "metadata": {},
   "source": [
    "#### LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-workstation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "british-defensive",
   "metadata": {},
   "source": [
    "### What can you say about the performance of the different model on the 2 datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-player",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "civic-colors",
   "metadata": {},
   "source": [
    "## What are your thoughts?\n",
    "> - Which model is overfitting ?\n",
    "> - Which model is underfittin?\n",
    "> - Which model is the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-killing",
   "metadata": {},
   "source": [
    "### Train the selected model, validate and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-acrobat",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "immune-magnet",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-shuttle",
   "metadata": {},
   "source": [
    "> From this step and forward we will only focus on the MAPE to monitor the performance of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_metrics(y_test, y_pred, y_train=None) -> dict:\n",
    "    metrics = {\n",
    "        'mape': mean_absolute_percentage_error(y_test, y_pred)\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-discretion",
   "metadata": {},
   "source": [
    "## 1 - Features selection : Importance Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the importance in a dataframe in descending order (from most important to less important)\n",
    "#plot the feature importance for the selected model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop on all features from 1 to n and keep track of the MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot MAPE vs number of features \n",
    "#what do you observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the top k features given the MAPE on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the model with the K best features and check the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-drawing",
   "metadata": {},
   "source": [
    "## 2 - Select the best Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-impact",
   "metadata": {},
   "source": [
    "In this part we will implement the grid search hyperparameter algorithm from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-darwin",
   "metadata": {},
   "source": [
    "#### Grid Search from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print lgbm parameters\n",
    "#hint place your cursor after the dot and hit tab\n",
    "lgbm_learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 150],\n",
    "              'num_leaves': [27, 31, 35]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ParameterGrid to print all the combinations of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop into this list of hyperparameters and get the best subset by logging MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a model with the best set of features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-simulation",
   "metadata": {},
   "source": [
    "# Try other hyperparameters search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-livestock",
   "metadata": {},
   "source": [
    "#### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how would you bring randomization on the search?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-gibson",
   "metadata": {},
   "source": [
    "#### Bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
